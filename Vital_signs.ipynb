{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4n8XyeZA94F"
      },
      "source": [
        "# ***CloudPhysician***\n",
        "# ***THE VITAL EXTRACTION CHALLENGE***\n",
        "\n",
        "### ***Extracting Patient Vitals from the given image of vital sign monitor using ML model, Image Processing and Optical Character Recognition.***\n",
        "\n",
        "## ***About the data***\n",
        "\n",
        "- The data consists of various images of health monitors. The classification dataset of the 4 types of monitors was used. Python code was used to randomly shuffle the images and pick 800 for training, and 200 for validation.\n",
        "The script created the following folder format:\n",
        "dataset - images - (train + val folders)\n",
        "        - labels - (train + val folders)\n",
        "All the image and label filenames are indexed by numbers. The various label files contain annotations for the images. An example annotation is:\n",
        "```\n",
        "0 0.78359375 0.14375 0.065625 0.09583333333333334\n",
        "3 0.89921875 0.25416666666666665 0.0453125 0.06944444444444445\n",
        "4 0.794140625 0.5027777777777778 0.08515625 0.10277777777777777\n",
        "5 0.778515625 0.6208333333333333 0.05546875 0.10277777777777777\n",
        "6 0.34765625 0.37083333333333335 0.678125 0.09166666666666666\n",
        "7 0.34765625 0.6201388888888889 0.6734375 0.08472222222222223\n",
        "8 0.348046875 0.5090277777777777 0.67578125 0.10694444444444444\n",
        "```\n",
        "\n",
        "- The first index is the label, and the 4 indices that follow are the normalized bounding box coordinates.\n",
        "The labels correspond to the indices of the matrix `['HR','SBP','DBP','MAP','SPO2','RR','HR_W','RR_W','SPO2_W']`\n",
        "\n",
        "- A dataset.yaml file is used to configure the model. It's format is:\n",
        "\n",
        "```\n",
        "path: dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 9\n",
        "\n",
        "names: `['HR','SBP','DBP','MAP','SPO2','RR','HR_W','RR_W','SPO2_W']`\n",
        "\n",
        "```\n",
        "## ***Getting Started***\n",
        "\n",
        "To use the model, just run the corresponding cells in the Jupyter notebook. The cells will download the pretrained model from GitHub, and use it to generate the bounding boxes which will later be used for OCR detection.\n",
        "\n",
        "## ***Neural Network Architecture***\n",
        "\n",
        "The bounding boxes will also be generated using the yolov5 model:\n",
        "\n",
        "\n",
        "\n",
        "***Why this architecture?***\n",
        "\n",
        "YOLOv5 (You Only Look Once version 5) is an object detection model used in computer vision tasks. It is a fast and accurate model that can perform object detection in real-time. YOLOv5 is the latest version in the YOLO series and is based on a single shot multi-box detection (SSD) architecture. It uses anchor boxes to predict bounding boxes for objects in an image and assigns a class label to each bounding box. YOLOv5 is known for its ability to detect objects in real-time and its relatively low computational requirements compared to other object detection models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Other architectures like the Faster-RCNN and SSD were tried, but the YoloV5 model was found to give the best (and fastest) results. Yolov5 allows us to use a state of the art architecture to quickly detect objects. The model was trained for the problem specification by using the custom dataset.\n",
        "\n",
        "## ***Training the model***\n",
        "The model was trained for 30 epochs and the following table was obtained:\n",
        "\n",
        "\n",
        "|Class   |  Images | Instances  |     P    |      R    |  mAP50   |  mAP50-95: 100% 10/10  |\n",
        "| ------ | ------- | ---------- | -------- | --------- | -------- | ---------------------- |\n",
        "|all     |   300   |    2161    |  0.783   |   0.957   |   0.837  |      0.669             |\n",
        "|HR      |   300   |     300    |  0.985   |       1   |   0.995  |      0.886             |\n",
        "|SBP     |   300   |     273    |      1   |   0.867   |   0.989  |      0.842             |\n",
        "|DBP     |   300   |     269    |  0.757   |       1   |   0.985  |      0.816             |\n",
        "|MAP     |   300   |     271    |   0.98   |       1   |   0.995  |      0.718             |\n",
        "|SPO2    |   300   |     281    |  0.762   |       1   |   0.988  |       0.88             |\n",
        "|RR      |   300   |     298    |  0.988   |   0.835   |    0.98  |      0.829             |\n",
        "|HR_W    |   300   |     163    |  0.539   |   0.994   |    0.54  |      0.379             |\n",
        "|RR_W    |   300   |     160    |  0.541   |   0.988   |   0.573  |      0.342             |\n",
        "|SPO2_W  |   300   |     146    |  0.492   |   0.932   |   0.494  |       0.33             |\n",
        "\n",
        "\n",
        "\n",
        "## ***Output of ML Model***\n",
        "\n",
        "Now, the best model was used to create bounding boxes for the various classes:<br>\n",
        "\n",
        "It outputs two matrices:\n",
        "- 1 dimensional matrix containing the labels of the predicted classes\n",
        "- 2 dimensional matrix, containing the bounding box coordinates (normalised x and y, width and height) and confidence for the predicted labels\n",
        "The predicted bounding boxes can also be displayed using `results.show()`\n",
        "\n",
        "The two matrices are processed and used later for OCR detection.\n",
        "\n",
        "## ***Processing of Image***\n",
        "\n",
        "- Using the bounding box coordinates image is cropped.\n",
        "- Cropped Image is then denoised using several denoising techniques and thresholded.\n",
        "- The threshold value chosen is the optimal value where we can binarize the image without losing the text.\n",
        "- Processed Image is then passed through OCR to predict the text in the image.\n",
        "- All the predicted value is reported in the form of python dictionary format.\n",
        "\n",
        "## ***OCR Configuration***\n",
        "\n",
        "```\n",
        "r\"--psm 8 --oem 3 -c tessedit_char_whitelist=0123456789/\"\n",
        "```\n",
        "\n",
        "This is a command-line argument for the Tesseract OCR engine. The arguments are as follows:\n",
        "\n",
        "- `--psm 8` : Page Segmentation Mode 8 is used to recognize a single digit as an instance of the character class.\n",
        "\n",
        "- `--oem 3` : The OCR Engine Mode 3 is used, which is a deep learning based recognition system.\n",
        "\n",
        "- `-c tessedit_char_whitelist=0123456789/` : The character whitelist is set to the numbers 0 to 9, allowing the OCR engine to recognize only these characters.\n",
        "\n",
        "The command line options are used to configure the behavior of the Tesseract OCR engine for optimal recognition of a specific type of text, in this case, single digits.\n",
        "\n",
        "## ***HR Wave Digitization***\n",
        "\n",
        "- The YoloV5 model is predicting the HR Wave and returning the coordinates of the bounding box.\n",
        "- After that the HR bounding box is cropped to give an image containing the HR for digital ECG analysis.\n",
        "- The function `digitalECG(path)` first reads an image, scales it, performs noise reduction and thresholding on it to obtain a binary image.\n",
        "- Then it finds the R peaks in the ECG signal by computing the mean, mode, and R_central_difference of the digitized ECG signal.\n",
        "- Finally, it plots the digital ECG signal, the thresholded image, and the original image.\n",
        "\n",
        "# ***Explaining Functions Used***\n",
        "\n",
        "## ***cropImage(img, normalized_coordinates)***\n",
        "- This function crops an image (2D numpy array `img`) using the normalized coordinates specified in `normalized_coordinates` (a list of 4 values, each representing a fraction of the total image size).\n",
        "- The function first calculates the width and height of the image using `img.shape[1]` and `img.shape[0]`, respectively.\n",
        "- Then it extracts a rectangular region of the image, defined by the top-left and bottom-right corners, which are computed by scaling the normalized coordinates by the image size.\n",
        "- The cropped region is returned as a new 2D numpy array.\n",
        "\n",
        "## ***crop_Image(img, normalized_coordinates)***\n",
        "- It is function similar to `cropImage`. It is specifically used to crop image of vital values by increasing the margin of cropped image so that edges of the numbers are not cut and is recognized perfectly for OCR.\n",
        "\n",
        "## ***text_r(img)***\n",
        "It is a function that performs optical character recognition (OCR) on an input image \"img\". The function does the following steps:\n",
        "\n",
        "- Defines the OCR configuration using the \"my_config\" variable, which specifies that only digits and \"/\" should be recognized, and sets the Page Segmentation Mode (psm) to 8 and the OCR Engine Mode (oem) to 3.\n",
        "\n",
        "- Removes noise from the image using the fastNlMeansDenoisingColored function from OpenCV library.\n",
        "  \n",
        "- Converts the image to binary format using the threshold function from OpenCV library.\n",
        "\n",
        "- Converts the binary image to grayscale using the cvtColor function from OpenCV library.\n",
        "\n",
        "- Uses the image_to_string function from the Tesseract OCR library to perform OCR on the grayscale image, and returns the recognized text.\n",
        "\n",
        "## ***hr_wave_detection(img, labels, coords)***\n",
        "This function takes an image, an array of labels and an array of coordinates as inputs. The function performs the following steps:\n",
        "\n",
        "- Loops over each label in the input \"labels\" array.\n",
        "- If the label is equal to 6, it calls the \"crop_image\" function to crop the image using the corresponding coordinates in the \"coords\" array.\n",
        "- Calls the \"cv2_imshow\" function to display the cropped image, which is supposed to be the HR waveform.\n",
        "\n",
        "## ***ocr(img, complete_coords, labels)***\n",
        "- This function performs optical character recognition (OCR) on an input image `img` using `complete_coords` and `labels` as parameters.\n",
        "- It creates an output dictionary `output_dict` and uses the reference list `reference` which has labels for the extracted data.\n",
        "- The function crops the input image using the `crop_image` function and performs text recognition on the cropped image using the `text_r` function.\n",
        "- The extracted text is stored in the `output_dict` with its corresponding label from the `reference` list.\n",
        "- The function then returns the `output_dict` after all 6 labels have been processed.\n",
        "\n",
        "## ***inference(image_path:str)***\n",
        "It is a function that takes an image file path as an input and returns the result of OCR. The function performs the following steps:\n",
        "\n",
        "- Calls the \"monitor_model\" function on the input image to get the locations of text regions in the image.\n",
        "- Calls the \"cropImage\" function to crop the image based on the locations of the text regions.\n",
        "- Calls the \"vitals_model\" function on the cropped image to get updated locations of the text regions.\n",
        "- Calls the \"ocr\" function on the cropped image and the updated text region locations to perform OCR on the image.\n",
        "- Returns the result of OCR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JVUwwTdHK8vg",
        "outputId": "5c04972c-4d41-418b-bfe8-3d15fe74e96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (23.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (8.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.1 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.3.1\u001b[0m\u001b[31m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 0s (26.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 128285 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard==2.4.1\n",
            "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (67.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (1.22.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (2.27.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (3.19.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (1.51.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (0.40.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1) (4.9)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard==2.4.1) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard==2.4.1) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.4.1) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1) (3.2.2)\n",
            "Installing collected packages: cachetools, google-auth, tensorboard\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.0\n",
            "    Uninstalling cachetools-5.3.0:\n",
            "      Successfully uninstalled cachetools-5.3.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.16.2\n",
            "    Uninstalling google-auth-2.16.2:\n",
            "      Successfully uninstalled google-auth-2.16.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires tensorboard<2.12,>=2.11, but you have tensorboard 2.4.1 which is incompatible.\n",
            "google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.35.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cachetools-4.2.4 google-auth-1.35.0 tensorboard-2.4.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping PIL as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: Pillow 8.4.0\n",
            "Uninstalling Pillow-8.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.9/dist-packages/PIL/*\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow-8.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libXau-00ec42fe.so.6.0.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libfreetype-804dfcff.so.6.18.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libharfbuzz-a69be65e.so.0.30000.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libjpeg-183418da.so.9.4.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/liblcms2-035b9744.so.2.0.12\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/liblzma-d540a118.so.5.2.5\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libopenjp2-430a98fc.so.2.4.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libpng16-213e245f.so.16.37.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libtiff-9ffe9659.so.5.7.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libwebp-d8a3db66.so.7.1.2\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libwebpdemux-f117ddb4.so.2.0.8\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libwebpmux-fe44437b.so.3.0.7\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libxcb-1122e22b.so.1.1.0\n",
            "    /usr/local/lib/python3.9/dist-packages/Pillow.libs/libz-dd453c56.so.1.2.11\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled Pillow-8.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-9.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!pip install pytesseract\n",
        "!pip install tensorflow==2.3.1\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install tensorboard==2.4.1\n",
        "!pip install torch\n",
        "!pip uninstall PIL\n",
        "!pip uninstall Pillow\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7XGQepdy3e1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pytesseract as tess\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "from IPython.display import Image\n",
        "import statistics as st\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy2FnY-ULIFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af75d51-e342-4d77-eb69-4b880ea5e7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AyxyQVnJh0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd59b4e9-c78f-4775-c6a8-e89842b37a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'VitalSIgnExtraction' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/FaizanRasoolQ/VitalSIgnExtraction.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKTxb8MyLKCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd43af6-07e3-4eee-a39c-dfce062134b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kU9n8SYLKmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c941165-e36d-4cbb-aca1-1584c9ae66a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.4.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (67.6.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n",
            "Installing collected packages: smmap, thop, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au3hd6rwnYm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a698b9ce-7a20-4382-a9b1-4d2c8dacac26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "monitor_model = torch.hub.load('/content/yolov5/', 'custom', path='/content/VitalSIgnExtraction/monitor_best.pt', source='local')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRIHinmV9qor"
      },
      "outputs": [],
      "source": [
        "def cropImage(img, normalized_coordinates):\n",
        "  img_width, img_height = img.shape[1],img.shape[0]\n",
        "  return img[int(normalized_coordinates[0][1]*img_height):int(normalized_coordinates[0][3]*img_height), int(normalized_coordinates[0][0]*img_width):int(normalized_coordinates[0][2]*img_width)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMzp2MjeHrqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fc8ac9-c80b-4938-b772-3407e18aaf35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7034398 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "vitals_model = torch.hub.load('/content/yolov5', 'custom', path='/content/VitalSIgnExtraction/vitalsign_best.pt', source='local')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIZZagC03iT3"
      },
      "outputs": [],
      "source": [
        "def text_r(img):\n",
        "    my_config = r\"--psm 11 --oem 3 -c tessedit_char_whitelist=0123456789\"\n",
        "    noise_reduced = cv.fastNlMeansDenoisingColored(img, None, 5, 10, 7, 21)\n",
        "    thresh, t_img = cv.threshold(noise_reduced, 200, 255, cv.THRESH_BINARY_INV)\n",
        "    t_img = cv.cvtColor(t_img, cv.COLOR_BGR2GRAY)\n",
        "    height, width, chaneels = img.shape\n",
        "    text = tess.image_to_string(t_img, config= my_config)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWU6O-zV4cX3"
      },
      "outputs": [],
      "source": [
        "def crop_Image(img, normalized_coordinates):\n",
        "    margin = 0.16\n",
        "    new_img = img[(int(normalized_coordinates[1]*img.shape[0])):(int(normalized_coordinates[3]*img.shape[0])), int(normalized_coordinates[0]*img.shape[1]):int(normalized_coordinates[2]*img.shape[1])]\n",
        "    return img[(int(normalized_coordinates[1]*img.shape[0]-margin*new_img.shape[0])):(int(normalized_coordinates[3]*img.shape[0]+margin*new_img.shape[0])), int(normalized_coordinates[0]*img.shape[1]-margin*new_img.shape[1]):int(normalized_coordinates[2]*img.shape[1]+margin*new_img.shape[1])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PyJgzEfayQ0"
      },
      "outputs": [],
      "source": [
        "def hr_wave_detection(img):\n",
        "  result=monitor_model(img)\n",
        "  labels, cord_thres = result.xyxyn[0][:, -1].cpu().numpy(), result.xyxyn[0][:, :-1].cpu().numpy()\n",
        "  new_image = cropImage(img, cord_thres)\n",
        "  vital_results=vitals_model(new_image)\n",
        "  labels, cord_thres = vital_results.xyxyn[0][:, -1].cpu().numpy(), vital_results.xyxyn[0][:, :-1].cpu().numpy()\n",
        "  #vital_results.show()\n",
        "  for i in range(len(labels)):\n",
        "    if(labels[i] == 6):\n",
        "      hr_wave = crop_Image(new_image, cord_thres[i])\n",
        "      cv2_imshow(hr_wave)\n",
        "      return hr_wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYYG8yG1XlO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be86d192-5193-4867-d2fa-8fa7691b4cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python-pil (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for python-pil\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.7/121.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m383.1/383.1 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m445.9/445.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m305.9/305.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m608.2/608.2 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.4/148.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.1/67.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.1/319.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.1/100.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.11.0 requires tensorboard<2.12,>=2.11, but you have tensorboard 2.4.1 which is incompatible.\n",
            "paddlepaddle 2.4.2 requires protobuf<=3.20.0,>=3.1.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.35.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q protobuf-compiler python-pil python-lxml\n",
        "!pip install -q paddlepaddle\n",
        "!pip install -q \"paddleocr>=2.0.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaXzTro1XzJr"
      },
      "outputs": [],
      "source": [
        "from paddleocr import PaddleOCR,draw_ocr\n",
        "ocr = PaddleOCR(use_angel_cls= True, lang = 'en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEDhkNKfXcOc"
      },
      "outputs": [],
      "source": [
        "def text_paddle(img):\n",
        "  result = ocr.ocr(img, cls=True)\n",
        "  if(len(result[0]) != 0):\n",
        "    return result[0][0][1][0]\n",
        "  else:\n",
        "    return 'ud'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cze6xnTPXNME"
      },
      "outputs": [],
      "source": [
        "def paddle_ocr(img, complete_coords, labels, path_str):\n",
        "  visited = np.zeros(6)\n",
        "  refernce = [\"HR\", \"SBP\", \"DBP\", \"MAP\", \"SPO2\", \"RR\"]\n",
        "  #monitor are the coords of the first out_put\n",
        "  output_dict = {}\n",
        "  j = 0\n",
        "  num = 0\n",
        "  for i in range(len(labels)):\n",
        "      if j == 6:\n",
        "          break\n",
        "      elif labels[i] < 6 and visited[int(labels[i])] == 0:\n",
        "              visited[int(labels[i])] = 1\n",
        "              ind_img = crop_Image(img, complete_coords[i])\n",
        "              cv2_imshow(ind_img)\n",
        "              #cv.imwrite('/content/drive/MyDrive/hundred/{}/{}'.format(path_str, num), ind_img)\n",
        "              #cv2_imshow(ind_img)\n",
        "              text = text_paddle(ind_img)\n",
        "              if len(text)!= 0:\n",
        "                #print(text[0])\n",
        "                if text[0]!='\\x0c':\n",
        "                  output_dict[refernce[int(labels[i])]] = text\n",
        "              j+=1\n",
        "      num +=1\n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHYiP4EdbhEL"
      },
      "outputs": [],
      "source": [
        "def ocr_shit(img, complete_coords, labels):\n",
        "  visited = np.zeros(6)\n",
        "  refernce = [\"HR\", \"SBP\", \"DBP\", \"MAP\", \"SPO2\", \"RR\"]\n",
        "  #monitor are the coords of the first out_put\n",
        "  output_dict = {}\n",
        "  j = 0\n",
        "  for i in range(len(labels)):\n",
        "\n",
        "      if j == 6:\n",
        "          break\n",
        "      elif labels[i] < 6 and visited[int(labels[i])] == 0:\n",
        "              visited[int(labels[i])] = 1\n",
        "              ind_img = crop_Image(img, complete_coords[i])\n",
        "              cv2_imshow(ind_img)\n",
        "              text = text_r(ind_img)\n",
        "              text = text.split('\\n')\n",
        "              if len(text)!= 0:\n",
        "                #print(text[0])\n",
        "                if text[0]!='\\x0c':\n",
        "                  output_dict[refernce[int(labels[i])]] = text[0]\n",
        "              j+=1\n",
        "\n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ1Otsol4Bq7"
      },
      "outputs": [],
      "source": [
        "def inference(image_path:str):\n",
        "  img=cv.imread(image_path)\n",
        "  result=monitor_model(img)\n",
        "  labels, cord_thres = result.xyxyn[0][:, -1].cpu().numpy(), result.xyxyn[0][:, :-1].cpu().numpy()\n",
        "  #result.show()\n",
        "  new_image = cropImage(img, cord_thres)\n",
        "  vital_results=vitals_model(new_image)\n",
        "  labels, cord_thres = vital_results.xyxyn[0][:, -1].cpu().numpy(), vital_results.xyxyn[0][:, :-1].cpu().numpy()\n",
        "  #vital_results.show()\n",
        "  result = paddle_ocr(new_image,cord_thres,labels, image_path)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLe4bzjPTnFt",
        "outputId": "f4e6e590-7e55-40c1-a91b-03ec2b777011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/hundred'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubw9l4jUWEjT",
        "outputId": "0f58a579-ba61-4cc7-9491-430d855fa19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hundred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWWtvkgjsgGE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "l_t = os.listdir('/content/drive/MyDrive/hundred')\n",
        "outputs = []\n",
        "# for i in range(10):\n",
        "#   d = inference(l_t[i])\n",
        "#   outputs.append(d)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(l_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txZ71TGFXpao",
        "outputId": "49a3cfcd-8b9b-4e03-882f-6bfc826001d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gnwvM8rM5IQ8",
        "outputId": "9afdc2f0-1251-4571-a483-a5129c348448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/hundred'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2bVt3TIO5Ay6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['image_path'] = np.nan\n",
        "df['label'] = np.nan\n",
        "df['text'] = np.nan"
      ],
      "metadata": {
        "id": "pV0EWd7-Poon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(image_path, df):\n",
        "  img=cv.imread(image_path)\n",
        "  result=monitor_model(img)\n",
        "  #result.show()\n",
        "  labels, cord_thres_m = result.xyxyn[0][:, -1].cpu().numpy(), result.xyxyn[0][:, :-1].cpu().numpy()\n",
        "  new_image = cropImage(img, cord_thres_m)\n",
        "  #cv2_imshow(new_image)\n",
        "  vital_results=vitals_model(new_image)\n",
        "  labels, cord_thres = vital_results.xyxyn[0][:, -1].cpu().numpy(), vital_results.xyxyn[0][:, :-1].cpu().numpy()\n",
        "  #print(cord_thres)\n",
        "  #print(labels)\n",
        "  for i in range(len(labels)):\n",
        "    if(labels[i] < 6):\n",
        "      ind_img = crop_Image(new_image, cord_thres[i])\n",
        "      #cv2_imshow(ind_img)\n",
        "      te = text_paddle(ind_img)\n",
        "      print(te)\n",
        "      df = df.append({'image_path': \"/content/drive/MyDrive/hundred/Croped_images/{}_{}.jpg\".format(image_path[:2], i), 'label': labels[i], 'text': te}, ignore_index=True)\n",
        "      cv.imwrite(\"/content/drive/MyDrive/hundred/Croped_images/{}_{}.jpg\".format(image_path[:2], i), ind_img)\n",
        "  df.to_csv('data_{}.csv'.format(image_path[:2]), index=False)"
      ],
      "metadata": {
        "id": "bxn7HlBH2_yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_dataset(l_t[0], df)"
      ],
      "metadata": {
        "id": "_6VmTXsizQKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvOK-BKSc-2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a725728-9d9a-403e-c49a-a538de911ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [image_path, label, text]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for l in range(2,10):\n",
        "  create_dataset(l_t[l], df)"
      ],
      "metadata": {
        "id": "FkCy5AAPRTrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(l_t.sort)\n",
        "print(l_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVb-bhGlVVu2",
        "outputId": "8ed3ad93-4063-4df8-c681-e0de85e37eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method sort of list object at 0x7f109c2a7940>\n",
            "['.ipynb_checkpoints', '0.jpg', '1.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '2.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '3.jpg', '30.jpg', '31.jpg', '32.jpg', '33.jpg', '34.jpg', '35.jpg', '36.jpg', '37.jpg', '38.jpg', '39.jpg', '4.jpg', '40.jpg', '41.jpg', '42.jpg', '43.jpg', '44.jpg', '45.jpg', '46.jpg', '47.jpg', '48.jpg', '49.jpg', '5.jpg', '50.jpg', '51.jpg', '52.jpg', '53.jpg', '54.jpg', '55.jpg', '56.jpg', '57.jpg', '58.jpg', '59.jpg', '6.jpg', '60.jpg', '61.jpg', '62.jpg', '63.jpg', '64.jpg', '65.jpg', '66.jpg', '67.jpg', '68.jpg', '69.jpg', '7.jpg', '70.jpg', '71.jpg', '72.jpg', '73.jpg', '74.jpg', '75.jpg', '76.jpg', '77.jpg', '78.jpg', '79.jpg', '8.jpg', '80.jpg', '81.jpg', '82.jpg', '83.jpg', '84.jpg', '85.jpg', '86.jpg', '87.jpg', '88.jpg', '89.jpg', '9.jpg', '90.jpg', '91.jpg', '92.jpg', '93.jpg', '94.jpg', '95.jpg', '96.jpg', '97.jpg', '98.jpg', '99.jpg', 'Croped_images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "id": "-3BwGuxpVJPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKswFhPN6dTD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def digitalECG(img):\n",
        "  #Scaling Image\n",
        "  scale_percent = 300 # percent of original size\n",
        "  width = int(img.shape[1] * scale_percent / 100)\n",
        "  height = int(img.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "  imgr=cv.resize(img, dim, interpolation = cv.INTER_CUBIC)\n",
        "  #Noise Reduction\n",
        "  noise_reduced = cv.fastNlMeansDenoisingColored(imgr, None, 5, 10, 7, 21)\n",
        "  noise_reduced = cv.cvtColor(noise_reduced, cv.COLOR_BGR2GRAY)\n",
        "  #Thresholding\n",
        "  thresh, t_img = cv.threshold(noise_reduced, 175, 255, cv.THRESH_BINARY)\n",
        "  y,x=t_img.shape\n",
        "  px = 1/plt.rcParams['figure.dpi']  # pixel in inches\n",
        "  digitized=np.zeros(x)\n",
        "  for i in range(x):\n",
        "      for j in range(y-1,-1,-1):\n",
        "        if t_img[j,i]==255:\n",
        "          digitized[i]=j\n",
        "          break\n",
        "  min=np.min(digitized[np.nonzero(digitized)])\n",
        "  max=np.max(digitized)\n",
        "  mode=st.mode(digitized[np.nonzero(digitized)])\n",
        "  mean=np.mean(digitized[np.nonzero(digitized)])\n",
        "  new=np.zeros(x)\n",
        "  prev_r=-1\n",
        "  PR_interval=50\n",
        "  R_central_difference=max-mean\n",
        "  #Finding R peaks\n",
        "  for i in range(x):\n",
        "    if i>0 and (digitized[i]-digitized[i-1])>R_central_difference and (prev_r==-1 or (i-prev_r)>=PR_interval):\n",
        "      new[i]=1\n",
        "      prev_r=i\n",
        "  #Plotting\n",
        "  plt.rcParams['figure.dpi']=100\n",
        "  f,axs=plt.subplots(3,1,figsize=(x*px, 6*y*px))\n",
        "  axs[0].margins(x=0)\n",
        "  axs[0].plot(range(len(new)),new)\n",
        "  axs[0].set_title('Digital ECG')\n",
        "  axs[1].imshow(t_img)\n",
        "  axs[1].set_title('Thresholded Image')\n",
        "  axs[2].imshow(imgr)\n",
        "  axs[2].set_title('Original Image')\n",
        "  plt.show()\n",
        "  return new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4MEHwrmtWzk"
      },
      "outputs": [],
      "source": [
        "img=cv.imread('/content/tridevdeoghar_icu_mon--4_2023_1_4_9_20_1.jpeg')\n",
        "image= hr_wave_detection(img)\n",
        "cv.imwrite('hrwave_img.jpeg',image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ir1QcY_6nb4"
      },
      "outputs": [],
      "source": [
        "arr=digitalECG(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onWZ1TcCxmyO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}